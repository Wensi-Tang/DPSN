{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tangw/Desktop/old/DPSN/time_series_proto/exp\n",
      "Building timeSeriesDataset for [ArrowHead] [train] with 3 classes ...\n",
      "BOSS ACC IS 0.7885714285714286\n",
      "0\n",
      "1\n",
      "2\n",
      "[[-1.16269775e+03 -7.78053625e+05 -7.94485062e+05]\n",
      " [-1.00220650e+06 -1.83346699e+04 -3.34757750e+05]\n",
      " [-9.74954000e+05 -2.58456625e+05 -2.11454180e+04]\n",
      " [-1.38028652e+04 -9.13316375e+05 -9.59437625e+05]\n",
      " [-7.66539750e+05 -1.19805371e+03 -3.16253844e+05]\n",
      " [-5.60111062e+05 -2.52682422e+05 -1.39792266e+04]\n",
      " [-3.73568828e+04 -4.83773844e+05 -4.61155562e+05]\n",
      " [-4.39444188e+05 -4.17159609e+04 -2.64104500e+05]\n",
      " [-1.04297125e+06 -3.60926031e+05 -2.48187676e+04]\n",
      " [-1.54962168e+04 -9.49246938e+05 -8.47814688e+05]\n",
      " [-1.05902662e+06 -2.79266992e+04 -3.21917219e+05]\n",
      " [-7.35127438e+05 -2.47089953e+05 -1.28118030e+03]\n",
      " [-2.88984180e+03 -8.44492438e+05 -8.14735250e+05]\n",
      " [-1.06260150e+06 -2.74673496e+04 -3.83991250e+05]\n",
      " [-5.42631625e+05 -2.41080672e+05 -1.74464863e+04]\n",
      " [-2.64980737e+03 -7.30976812e+05 -7.80643000e+05]\n",
      " [-6.41139812e+05 -5.55688379e+03 -2.34847531e+05]\n",
      " [-8.26488438e+05 -2.67293062e+05 -3.41710571e+03]\n",
      " [-3.34349365e+03 -6.62695438e+05 -6.56727875e+05]\n",
      " [-1.23302275e+06 -5.97139141e+04 -4.11087750e+05]\n",
      " [-5.83393875e+05 -2.56993812e+05 -1.05788438e+04]\n",
      " [-1.85025039e+04 -5.78237875e+05 -5.33388750e+05]\n",
      " [-5.17393281e+05 -3.11049297e+04 -3.49876750e+05]\n",
      " [-4.61286750e+05 -2.37888625e+05 -3.94752461e+04]\n",
      " [-1.26419326e+04 -9.38643250e+05 -9.50258375e+05]\n",
      " [-6.46688125e+05 -6.49913916e+03 -2.20663875e+05]\n",
      " [-5.10400188e+05 -2.82883344e+05 -2.44846543e+04]\n",
      " [-8.55172461e+03 -6.22304375e+05 -5.97910500e+05]\n",
      " [-5.61389812e+05 -1.43295684e+04 -2.55313781e+05]\n",
      " [-9.74187375e+05 -3.80944969e+05 -1.69638809e+04]\n",
      " [-1.10053730e+04 -9.39570750e+05 -8.81781062e+05]\n",
      " [-6.75932312e+05 -3.35092480e+03 -3.04688500e+05]\n",
      " [-8.96273000e+05 -3.85403250e+05 -1.18130635e+04]\n",
      " [-1.35616689e+04 -7.06469250e+05 -8.25573812e+05]\n",
      " [-6.44830125e+05 -6.20064355e+03 -2.22062906e+05]\n",
      " [-1.07252188e+06 -4.21924281e+05 -3.19962656e+04]]\n",
      "0\n",
      "1\n",
      "2\n",
      "tensor([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,\n",
      "        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])\n",
      "[array(0), array(4), array(11)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import shutil\n",
    "import os, sys, time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "sys.path.append(os.getcwd()[:-3] + 'lib')\n",
    "print(os.getcwd())\n",
    "from datasets import timeSeriesDataset, FewShotSampler\n",
    "from configs import get_parser, Logger, time_string, convert_secs2time, AverageMeter, obtain_accuracy\n",
    "from models import euclidean_dist\n",
    "import models\n",
    "import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_SFA_train_data(name):\n",
    "    args_dataset_root = os.getcwd()[:-21]+'SFA_Python-master/test/BOSS_feature_Data_pyts/'\n",
    "    train_dataset = timeSeriesDataset(args_dataset_root, 'train', name, 1, 10)\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def random_choice(s_idxs,k):\n",
    "    result=np.random.choice(s_idxs.size(0), k, replace=False)\n",
    "    return s_idxs[result]\n",
    "    \n",
    "\n",
    "\n",
    "def get_log_path(name, ratio_number, ind_number):\n",
    "    log_path = os.getcwd()[:-3] + 'logs/5shot_linear_transform/' + name + '/' + str(ratio_number) + '/' + str(\n",
    "        ind_number)\n",
    "    log_path = log_path + '/' + os.listdir(log_path)[0]\n",
    "    log_path = log_path + '/baseline_classifier/model_linear_transform_lst.pth'\n",
    "    return log_path\n",
    "\n",
    "\n",
    "\n",
    "def save_to_file(sentence, dataset_name, log_path=None):\n",
    "    father_path = './test_accuracy_log_all_as_proto/' + dataset_name\n",
    "    if not os.path.exists(father_path):\n",
    "        os.makedirs(father_path)\n",
    "    path = father_path + '/' + dataset_name + 'NN_list_log.txt'\n",
    "    if log_path != None:\n",
    "        path = log_path\n",
    "    with open(path, \"a\") as myfile:\n",
    "        myfile.write(sentence + '\\n')\n",
    "    return path\n",
    "\n",
    "\n",
    "name_list=[\n",
    "    'ArrowHead',\n",
    "    'BME',\n",
    "    'CBF',\n",
    "    'Chinatown',\n",
    "    'ECG200',\n",
    "    'GunPoint',\n",
    "    'GunPointAgeSpan',\n",
    "    'GunPointOldVersusYoung',\n",
    "    'ItalyPowerDemand',\n",
    "    'MoteStrain',\n",
    "    'Plane',\n",
    "    'SonyAIBORobotSurface1',\n",
    "    'SonyAIBORobotSurface2',\n",
    "    'SyntheticControl',\n",
    "    'ToeSegmentation1',\n",
    "    'TwoLeadECG',\n",
    "    'UMD',\n",
    "    'Wine',\n",
    "  ]\n",
    "ratio_number_list = [1]\n",
    "ind_number_list = [10]\n",
    "args_arch = 'linear_transform'\n",
    "args_dataset_root = os.getcwd()[:-21]+'SFA_Python-master/test/BOSS_feature_Data_pyts/'\n",
    "using_proto = True\n",
    "pick_all =True\n",
    "\n",
    "for name in name_list:\n",
    "    for ind_radio, ratio_number in enumerate(ratio_number_list):\n",
    "        for ind, ind_number in enumerate(ind_number_list):\n",
    "                model_lst_path = get_log_path(name, ratio_number, ind_number)\n",
    "                \n",
    "                train_dataset = timeSeriesDataset(args_dataset_root, 'train', name, ratio_number, ind_number)\n",
    "                model = models.__dict__[args_arch](train_dataset.fea_dim,256,64)\n",
    "                model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "                checkpoint = torch.load(model_lst_path)\n",
    "                start_epoch = checkpoint['epoch'] + 1\n",
    "                best_acc = checkpoint['best_acc']\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                model.eval()\n",
    "                \n",
    "                \n",
    "                feas = train_dataset.feature\n",
    "                labels = train_dataset.label\n",
    "                embs = model(feas)\n",
    "                \n",
    "                cpu_labels = labels.cpu().tolist()\n",
    "                idxs_dict = defaultdict(list)\n",
    "                for i, l in enumerate(cpu_labels):\n",
    "                    idxs_dict[l].append(i)\n",
    "                idxs_dict = dict(sorted(idxs_dict.items()))\n",
    "                grouped_s_idxs = []\n",
    "                for lab, idxs in idxs_dict.items():\n",
    "                    print(lab)\n",
    "                    grouped_s_idxs.append(torch.LongTensor(idxs[:]))\n",
    "                proto_lst = [torch.mean(embs[s_idxs], dim=0) for s_idxs in grouped_s_idxs]\n",
    "                proto = torch.stack(proto_lst, dim=0)\n",
    "                logits = - euclidean_dist(embs, proto, transform=True).view(labels.size(0), len(proto))\n",
    "                dis = logits.cpu().detach().numpy()\n",
    "             \n",
    "                print(dis)\n",
    "                labind= 0\n",
    "                result = []\n",
    "                for s_idxs in grouped_s_idxs:\n",
    "                    temp = dis[s_idxs]\n",
    "                    print(labind)\n",
    "                    result.append(s_idxs[np.argmax(temp,axis = 0)[labind]].numpy())\n",
    "                    labind = labind + 1\n",
    "\n",
    "                print(labels)\n",
    "                print(result)\n",
    "                sentence = ''\n",
    "                for i in result:\n",
    "                    sentence = sentence+str(i)+'\\t'\n",
    "                save_to_file(sentence,name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
