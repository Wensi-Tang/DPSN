{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from os.path import dirname\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from keras.optimizers import Adagrad\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from tslearn.shapelets import ShapeletModel, grabocka_params_to_shapelet_size_dict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def covert_list_to_dic(XX_list):\n",
    "    result_dic ={}\n",
    "    for i,item in enumerate(XX_list):\n",
    "        result_dic[item]=i\n",
    "    return result_dic\n",
    "\n",
    "def load_st_result(name, ratio_number_list, ind_number_list  = [0,1,2,3,4,5,6,7,8,9]):\n",
    "    father_path = './ST_acc_log/' + name\n",
    "    path = father_path + '/' + name + '_log.txt'\n",
    "    ratio_dic = covert_list_to_dic(ratio_number_list)\n",
    "    ind_dic = covert_list_to_dic(ind_number_list)\n",
    "    proto_result = np.zeros([len(ratio_number_list), len(ind_number_list)])\n",
    "    try:\n",
    "        f = open(path, \"r\")\n",
    "        for x in f:\n",
    "            temp = x.split('\\t')\n",
    "            if float(temp[3]) == 1:\n",
    "                proto_result[-1:, :] = np.ones((1, len(ind_number_list))) * float(temp[-1])\n",
    "                continue\n",
    "\n",
    "            proto_result[ratio_dic[float(temp[3])]][ind_dic[float(temp[5])]] = float(temp[-1])\n",
    "    except:\n",
    "        print(name, 'cannot find')\n",
    "\n",
    "    return proto_result\n",
    "\n",
    "\n",
    "def save_Super_to_log(sentence, dataset_name):\n",
    "    father_path = './ST_super_log/' + dataset_name\n",
    "    if os.path.exists(father_path):\n",
    "        shutil.rmtree(father_path)\n",
    "    if not os.path.exists(father_path):\n",
    "        os.makedirs(father_path)\n",
    "    path = father_path + '/' + dataset_name + '_log.txt'\n",
    "    with open(path, \"a\") as myfile:\n",
    "        myfile.write(sentence + '\\n')\n",
    "\n",
    "def load_super_log(dataset_name):\n",
    "    father_path = './ST_super_log/' + dataset_name\n",
    "    path = father_path + '/' + dataset_name + '_log.txt'\n",
    "    try:\n",
    "        f = open(path, \"r\")\n",
    "        for x in f:\n",
    "            return str(x)\n",
    "    except:\n",
    "        print(name, 'cannot find')\n",
    "\n",
    "\n",
    "\n",
    "def save_to_log(sentence, dataset_name):\n",
    "    father_path = './ST_acc_log/' + dataset_name\n",
    "    if not os.path.exists(father_path):\n",
    "        os.makedirs(father_path)\n",
    "    path = father_path + '/' + dataset_name + '_log.txt'\n",
    "    with open(path, \"a\") as myfile:\n",
    "        myfile.write(sentence + '\\n')\n",
    "\n",
    "def TSC_data_loader(dataset_name):\n",
    "    Train_dataset = np.loadtxt(\n",
    "        dirname(os.getcwd()) + '/datasets/UCRArchive_2018/' + dataset_name + '/' + dataset_name + '_TRAIN.tsv')\n",
    "    Test_dataset = np.loadtxt(\n",
    "        dirname(os.getcwd()) + '/datasets/UCRArchive_2018/' + dataset_name + '/' + dataset_name + '_TEST.tsv')\n",
    "    Train_dataset = Train_dataset.astype(np.float32)\n",
    "    Test_dataset = Test_dataset.astype(np.float32)\n",
    "\n",
    "    X_train = Train_dataset[:, 1:]\n",
    "    y_train = Train_dataset[:, 0:1]\n",
    "\n",
    "    X_test = Test_dataset[:, 1:]\n",
    "    y_test = Test_dataset[:, 0:1]\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(np.squeeze(y_train, axis=1))\n",
    "    y_train = le.transform(np.squeeze(y_train, axis=1))\n",
    "    y_test = le.transform(np.squeeze(y_test, axis=1))\n",
    "\n",
    "    # X_train = np.nan_to_num(X_train)\n",
    "    # X_test  = np.nan_to_num(X_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def shapelet_best_predict(X_train, y_train, X_test, y_test):\n",
    "    X_train = TimeSeriesScalerMinMax().fit_transform(X_train)\n",
    "    X_test = TimeSeriesScalerMinMax().fit_transform(X_test)\n",
    "    \n",
    "    r_list = [2,4,6,8,12]\n",
    "    result_list = [0 for i in range(len(r_list))]\n",
    "    for r_number_index, r_number in enumerate(r_list):\n",
    "        try:\n",
    "            shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=X_train.shape[0],\n",
    "                                                       ts_sz=X_train.shape[1],\n",
    "                                                       n_classes=len(set(y_train)),\n",
    "                                                       l=0.1,\n",
    "                                                       r=r_number)\n",
    "\n",
    "            shp_clf = ShapeletModel(n_shapelets_per_size=shapelet_sizes,\n",
    "                            optimizer=Adagrad(lr=.1),\n",
    "                            weight_regularizer=.01,\n",
    "                            max_iter=50,\n",
    "                            verbose_level=0)\n",
    "            shp_clf.fit(X_train, y_train)\n",
    "            y_predict = shp_clf.predict(X_train)\n",
    "            result_list[r_number_index] = accuracy_score(y_predict,y_train)\n",
    "        except:\n",
    "            print(\"error in \",r_number)\n",
    "    \n",
    "    best_r_ind =np.argmax(result_list)  \n",
    "    shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=X_train.shape[0],\n",
    "                                                       ts_sz=X_train.shape[1],\n",
    "                                                       n_classes=len(set(y_train)),\n",
    "                                                       l=0.1,\n",
    "                                                       r=r_list[best_r_ind])\n",
    "    \n",
    "    shp_clf.fit(X_train, y_train)\n",
    "    y_predict = shp_clf.predict(X_test)\n",
    "    result = accuracy_score(y_predict,y_test)\n",
    "    return result , r_list[best_r_ind]\n",
    "    \n",
    "\n",
    "def shapelet_predict(X_train, y_train, X_test, y_test,r_number):\n",
    "    X_train = TimeSeriesScalerMinMax().fit_transform(X_train)\n",
    "    X_test = TimeSeriesScalerMinMax().fit_transform(X_test)\n",
    "    shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=X_train.shape[0],\n",
    "                                                       ts_sz=X_train.shape[1],\n",
    "                                                       n_classes=len(set(y_train)),\n",
    "                                                       l=0.1,\n",
    "                                                       r=r_number)\n",
    "\n",
    "    shp_clf = ShapeletModel(n_shapelets_per_size=shapelet_sizes,\n",
    "                            optimizer=Adagrad(lr=.1),\n",
    "                            weight_regularizer=.01,\n",
    "                            max_iter=50,\n",
    "                            verbose_level=0)\n",
    "    shp_clf.fit(X_train, y_train)\n",
    "    y_predict = shp_clf.predict(X_test)\n",
    "    acc = accuracy_score(y_predict,y_test)\n",
    "    \n",
    "    return acc \n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0) \n",
    "name_list = [\n",
    "    'ArrowHead',\n",
    "    'BME',\n",
    "    'CBF',\n",
    "    'Chinatown',\n",
    "    'ECG200',\n",
    "    'GunPoint',\n",
    "    'GunPointAgeSpan',\n",
    "    'GunPointOldVersusYoung',\n",
    "    'ItalyPowerDemand',\n",
    "    'MoteStrain',\n",
    "    'Plane',\n",
    "    'SonyAIBORobotSurface1',\n",
    "    'SonyAIBORobotSurface2',\n",
    "    'SyntheticControl',\n",
    "    'ToeSegmentation1',\n",
    "    'TwoLeadECG',\n",
    "    'UMD',\n",
    "    'Wine',\n",
    "]    \n",
    "\n",
    "train_ratio_list = [0.1,0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "for name in name_list:\n",
    "    print(name)\n",
    "    X_train_ori, y_train_ori, X_test, y_test= TSC_data_loader(name)\n",
    "    result , shapelet_number = shapelet_best_predict(X_train_ori, y_train_ori, X_test, y_test)\n",
    "    sentence = str(shapelet_number)\n",
    "    save_Super_to_log(sentence, name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
